{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments implementation\n",
    "Implementing the convolutional neural networks models and experiments implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "global data_folder,dataset_file\n",
    "data_folder = \"../data/\"\n",
    "dataset_file= [\"cullpdb+profile_6133.npy.gz\",\"cullpdb+profile_5926_filtered.npy.gz\",\"CB513.npy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading procedures\n",
    "#### Explanation\n",
    "Dataset split\n",
    "int the dataset cullpdb+profile_5926.npy.gz\n",
    "the subset  division of the data set is as follows:\n",
    "[0,5430) training\n",
    "[5435,5690) test\n",
    "[5690,5926) validation\n",
    "\n",
    "\n",
    "\n",
    "The subset division of the cullpdb+profile_6133.npy.gz is as follows:\n",
    "The dataset division for the first cullpdb+profile_6133.npy.gz dataset is\n",
    "[0,5600) training\n",
    "[5605,5877) test\n",
    "[5877,6133) validation\n",
    "\n",
    "\n",
    "In both datasets cullpdb+profile_5926.npy.gz and cullpdb+profile_6133.npy.gz\n",
    "The features in the dataset can be found as follows:\n",
    "\n",
    "It is currently in numpy format as a (N protein x k features) matrix.\n",
    "You can reshape it to (N protein x 700 amino acids x 57 features) first.\n",
    "\n",
    "The 57 features are:\n",
    "[0,22): amino acid residues, with the order of 'A', 'C', 'E', 'D', 'G', 'F', 'I', 'H', 'K', 'M', 'L', 'N', 'Q', 'P',\n",
    "                                               'S', 'R', 'T', 'W', 'V', 'Y', 'X','NoSeq'\n",
    "[22,31): Secondary structure labels, with the sequence of 'L', 'B', 'E', 'G', 'I', 'H', 'S', 'T','NoSeq'\n",
    "[31,33): N- and C- terminals;\n",
    "[33,35): relative and absolute solvent accessibility, used only for training.\n",
    "        (absolute accessibility is thresholded at 15; relative accessibility\n",
    "        is normalized by the largest accessibility value in a protein and thresholded at 0.15;\n",
    "        original solvent accessibility is computed by DSSP)\n",
    "[35,57): sequence profile. Note the order of amino acid residues is ACDEFGHIKLMNPQRSTVWXY and\n",
    "         it is different from the order for amino acid residues\n",
    "\n",
    "The last feature of both amino acid residues and secondary structure labels just mark end of the protein sequence.\n",
    "[22,31) and [33,35) are hidden during testing.\n",
    "\n",
    "source: https://www.princeton.edu/~jzthree/datasets/ICML2014/dataset_readme.txt\n",
    "accessed in 29/06/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildScoringMatrix():\n",
    "    \"\"\"\n",
    "    Building protein scoring matrix and creating a dictionary with the aminoacids and each of their corresponding\n",
    "    rows in the matrix\n",
    "    To convert the one hot encoding of the aminoacids for simplicity it can be made a dot product with the matrix\n",
    "    M with the onehot encoding of the aminoacid.\n",
    "    :return: Scoring Matrix M, positions of the aminoacids \n",
    "    \"\"\"\n",
    "    positions = {'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,\n",
    "                 'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
    "    M=[[4,   0, -1, -2,  0, -1, -2, -3, -1, -1,  1,  0, -2, -2, -1, -2, -1, -2, -2, -1],\n",
    "       [-1, -2, -3 ,-3 ,-3 ,-3, -4, -4,  8, -3, -1, -1, -3, -2, -1, -2, -1, -2, -2, -1],\n",
    "       [3,   2, -2 ,-2 ,-1 ,-1, -3, -3, -1, -1,  1,  3, -2, -1, -1, -2, -1, -2, -2, -1],\n",
    "       [2,  -2,  1,  0,  2,  0,  3, -2, -2, -1,  0, -1,  0, -2, -2, -2, -2, -2, -3, -2],\n",
    "       [0,  -1, -1, -2, -1, -1, -2, -3, -1, -1,  3,  4, -2,  0, -1, -2, -1, -1, -1, -1],\n",
    "       [0,  -3,  3,  1,  4,  1, -1, -3, -3, -1, -2,  0, -1, -3, -2, -3, -3, -3, -3, -3],\n",
    "       [0,  -1, -1, -2, -1, -1, -2, -3, -1, -1, -3,  4, -2,  0, -1, -2, -1, -1, -1, -1],\n",
    "       [-1, -2, -3, -3, -3, -3, -4, -4,  8, -3, -1, -1, -3, -2, -2, -2, -1, -2, -2, -1],\n",
    "       [3,   0, -2, -2, -1, -1, -2, -3, -1, -1,  3,  1, -2, -1, -1, -1, -1, -1, -1, -1],\n",
    "       [1,  -1 ,-2 ,-2 ,-1 ,-1, -3, -3, -1, -1,  4,  3, -2,  0,  0, -1, -1, -1, -1, -1],\n",
    "       [0,   6, -4, -4, -3 ,-3, -3, -3, -2, -3,  0, -2, -3, -1, -2, -2, -2, -3, -2, -2],\n",
    "       [0,  -3 , 1,  4,  1 , 2,  0, -2, -3, -1, -2, -1, -1, -3, -2, -3, -2, -2, -4, -3],\n",
    "       [2,   0 ,-2, -2, -1, -2, -3, -3, -1, -1,  4,  1, -2,  0,  0, -1,  0, -1, -1,  0],\n",
    "       [-2, -1 ,-3 ,-4 ,-3, -3, -4, -4, -2, -4,  0, -1, -3,  3,  0, -1, -1, -2,  6,  1],\n",
    "       [0 ,  6, -4, -4, -3, -3, -3, -3, -2, -3,  0, -2, -3, -1, -2, -2, -2, -3, -2, -2],\n",
    "       [1 , -1 ,-2 ,-2, -1, -1, -3, -2, -1, -2,  1,  3, -2,  0,  4, -1,  0,  0, -1,  0],\n",
    "       [0,  -2,  1, -1,  2,  0, -2, -3, -3, -1,  2,  3, -1, -1, -1, -2, -1, -2, -2, -1],\n",
    "       [0,  -3,  3,  1,  4,  1, -1, -3, -3, -1, -2,  0, -1, -3, -2, -3, -3, -3, -3, -3],\n",
    "       [0 , -1 ,-2, -2, -1, -1, -3, -3, -1, -2,  2,  3, -2,  0,  0, -1,  3,  1, -1,  0],\n",
    "       [0,  -3,  3,  1,  4,  1, -1, -3, -3, -1, -2,  0, -1, -3, -2, -3, -3, -3, -3, -3],\n",
    "       [3,   0, -2, -2, -1, -1, -3, -3, -1, -1,  3,  1, -2,  0,  0, -1, -1, -1, -1, -1]]\n",
    "    return M, positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_reshape(ds_idx=0):\n",
    "    global data_folder, dataset_file\n",
    "    ds = np.load(data_folder+dataset_file[ds_idx])\n",
    "    print(\"[INFO] The data set \"+dataset_file[ds_idx]+\"  has been loaded\")\n",
    "    ds = ds.reshape(-1,700,57)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_samples(data):\n",
    "    \"\"\"\n",
    "    As indicated in the description above, the labels are then extracted from the\n",
    "    fetures loaded with the data and return with the data reshaped\n",
    "    note that the N- and C- terminals are being ignored as well as the relative and absolute solvent accessibility\n",
    "    and the sequence profile.\n",
    "    :param data: The data loaded\n",
    "    :return: data, labels\n",
    "    \"\"\"\n",
    "    labels_start = 22\n",
    "    labels_end = 31\n",
    "    aminoacids_end = 22\n",
    "\n",
    "    data_samples = data[:,:,:aminoacids_end]\n",
    "    labels  =data[:,:,labels_start:labels_end]\n",
    "    labels  = np.array([np.argmax(labels[i,:]) for i in range(labels.shape[0])])\n",
    "    return data_samples,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_scoring_matrix(data):\n",
    "    \"\"\"\n",
    "        Using scoring matrix defined in buildScoringMatrix in order to replace the one hot enconding\n",
    "        of the aminoacid with the encoding defined in the scoring matrix.\n",
    "        return: data set with the one hot encoded samples replaced by their corespondin position in the scoring matrix\n",
    "    \"\"\"\n",
    "    M, _ = buildScoringMatrix()\n",
    "    newData = [[]]\n",
    "    for i,d in enumerate(data):\n",
    "        for aminoacid in d:\n",
    "            aminoacid = np.dot(aminoacid,M).tolist()\n",
    "            #Replacing one hot enconding with aminoacid encoding from the scoring matrix\n",
    "            newData[i].append(aminoacid)\n",
    "        newData.append([])\n",
    "    return np.array(newData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split(ds_opc):\n",
    "    \"\"\"\n",
    "    :param ds_opc: data set that has been selected\n",
    "           The ds_opc must indicate an option choice between the following sets\n",
    "           CB513.npy,cullpdb+profile_6133.npy.gz,cullpdb+profile_5926_filtered.npy.gz\n",
    "    :return:  train, test and validation sets (Already shuffled)\n",
    "    \"\"\"\n",
    "    assert type(ds_opc) == int\n",
    "    assert ds_opc < 3 and ds_opc >= 0\n",
    "    print(\"[INFO] The dataset \" + dataset_file[ds_opc] + \"Has been selected\")\n",
    "\n",
    "    data = load_and_reshape(ds_opc)\n",
    "    # Shuffling the data\n",
    "    data = sklearn.utils.shuffle(data)\n",
    "\n",
    "    data, labels = extract_labels_from_samples(data)\n",
    "\n",
    "    train_set = None\n",
    "    train_labels = None\n",
    "\n",
    "    test_set = None\n",
    "    test_labels = None\n",
    "\n",
    "    valid_set = None\n",
    "    valid_labels = None\n",
    "\n",
    "    if ds_opc == 0:\n",
    "        # spliting the cullpdb+profile_6133.npy.gz\n",
    "        train_idx = [0, 5430]\n",
    "        test_idx = [5435, 5690]\n",
    "        valid_idx = [5690, 5926]\n",
    "\n",
    "        train_set = data[:train_idx[1], :, :]\n",
    "        train_labels = labels[: train_idx[1]]\n",
    "\n",
    "        test_set = data[test_idx[0]:test_idx[1], :, :]\n",
    "        test_labels = labels[test_idx[0]:test_idx[1]]\n",
    "\n",
    "        valid_set = data[valid_idx[0]:valid_idx[1], :, :]\n",
    "        valid_labels = labels[valid_idx[0]:valid_idx[1]]\n",
    "\n",
    "    elif ds_opc == 1:\n",
    "        # spliting the cullpdb+profile_5926_filtered.npy.gz\n",
    "        train_idx = [0, 5600]\n",
    "        test_idx = [5605, 5877]\n",
    "        valid_idx = [5877, 6133]\n",
    "\n",
    "        train_set = data[:train_idx[1], :, :]\n",
    "        train_labels =labels[ :train_idx[1]]\n",
    "\n",
    "        test_set = data[test_idx[0]:test_idx[1], :, :]\n",
    "        test_labels = labels[test_idx[0]:test_idx[1]]\n",
    "\n",
    "        valid_set = data[valid_idx[0]:valid_idx[1], :, :]\n",
    "        valid_labels = labels[valid_idx[0]:valid_idx[1]]\n",
    "\n",
    "    elif ds_opc == 2:\n",
    "        # spliting CDB513\n",
    "        n_samples = 513\n",
    "        # Spliting the dataset in 70% for train, 20% for test and 10% for validation\n",
    "        train_val = int(n_samples * 0.7)\n",
    "        test_val = train_val + int(n_samples * 0.2)\n",
    "        valid_val = test_val + int(n_samples * 0.1)\n",
    "        train_idx = [0, train_val]\n",
    "        test_idx = [train_val, test_val]\n",
    "        valid_idx = [test_val, valid_val]\n",
    "\n",
    "        train_set = data[:train_idx[1], :, :]\n",
    "        train_labels = labels[: train_idx[1]]\n",
    "\n",
    "        test_set = data[test_idx[0]:test_idx[1], :, :]\n",
    "        test_labels = labels[test_idx[0]:test_idx[1]]\n",
    "\n",
    "        valid_set = data[valid_idx[0]:valid_idx[1], :, :]\n",
    "        valid_labels = labels[valid_idx[0]:valid_idx[1]]\n",
    "\n",
    "    return train_set,train_labels, test_set,test_labels, valid_set,valid_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The dataset CB513.npyHas been selected\n",
      "[INFO] The data set CB513.npy  has been loaded\n"
     ]
    }
   ],
   "source": [
    "train_set,train_labels,test_set,test_labels,valid_set,valid_labels = load_and_split(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
