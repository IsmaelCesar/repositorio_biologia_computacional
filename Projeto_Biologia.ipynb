{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_Biologia.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4mOjp4IZhht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, ActivityRegularization, BatchNormalization, Conv2D, AveragePooling2D, Flatten\n",
        "from keras.layers import Input,Add,MaxPooling2D,LSTM,TimeDistributed\n",
        "from keras.models  import Model\n",
        "from keras import regularizers\n",
        "from keras.optimizers import Adamax\n",
        "import keras\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "janela = 25 #valor impar\n",
        "size = int(janela/2) #tamanho a ser incrementado nas laterais\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypmv5ArKZhiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(X):\n",
        "    data = X['prot']\n",
        "    classes = X['class']\n",
        "    positions = {'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,\n",
        "                 'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
        "    classes_converter = {'-': 0, 'E':1, 'H':2}\n",
        "    res = []\n",
        "    for i in range(len(data)):\n",
        "        for j in range(len(data[i])):\n",
        "            res.append(int(positions[data[i][j]])+1)\n",
        "    for i in range(size):\n",
        "        res.insert(0, 0)\n",
        "        res.append(0)\n",
        "    data =[]\n",
        "    for i in range(len(X['prot'])):\n",
        "        data.append(res[i:janela+i])\n",
        "        data[i].append(classes_converter[classes[i]])\n",
        "    columns = [[]]*(janela+1)\n",
        "    for i in range(janela):\n",
        "        columns[i] = \"Element\" + str(i)\n",
        "    columns[janela] = 'Class'\n",
        "    data = pd.DataFrame(data, columns = columns)\n",
        "    return data\n",
        "\n",
        "def load_data():\n",
        "    proteins = pd.read_csv('cb513.csv',sep='\\s*,\\s*')\n",
        "    res = load(proteins.iloc[0])\n",
        "    for i in range(1,len(proteins)):\n",
        "        aux = load(proteins.iloc[i])\n",
        "        res = res.append(aux,ignore_index = True)\n",
        "    print(res)\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kg3flBKyL-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildScoringMatrix():\n",
        "    \"\"\"\n",
        "    Building protein scoring matrix and creating a dictionary with the aminoacids and each of their corresponding\n",
        "    rows in the matrix\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    positions = {'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,\n",
        "                 'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
        "    res = ['A','C','D','E','F','G','H','I','K','L','M','N',\n",
        "                 'P','Q','R','S','T','V','W','Y']\n",
        "    M=[[4,   0, -1, -2,  0, -1, -2, -3, -1, -1,  1,  0, -2, -2, -1, -2, -1, -2, -2, -1],\n",
        "       [-1, -2, -3 ,-3 ,-3 ,-3, -4, -4,  8, -3, -1, -1, -3, -2, -1, -2, -1, -2, -2, -1],\n",
        "       [3,   2, -2 ,-2 ,-1 ,-1, -3, -3, -1, -1,  1,  3, -2, -1, -1, -2, -1, -2, -2, -1],\n",
        "       [2,  -2,  1,  0,  2,  0,  3, -2, -2, -1,  0, -1,  0, -2, -2, -2, -2, -2, -3, -2],\n",
        "       [0,  -1, -1, -2, -1, -1, -2, -3, -1, -1,  3,  4, -2,  0, -1, -2, -1, -1, -1, -1],\n",
        "       [0,  -3,  3,  1,  4,  1, -1, -3, -3, -1, -2,  0, -1, -3, -2, -3, -3, -3, -3, -3],\n",
        "       [0,  -1, -1, -2, -1, -1, -2, -3, -1, -1, -3,  4, -2,  0, -1, -2, -1, -1, -1, -1],\n",
        "       [-1, -2, -3, -3, -3, -3, -4, -4,  8, -3, -1, -1, -3, -2, -2, -2, -1, -2, -2, -1],\n",
        "       [3,   0, -2, -2, -1, -1, -2, -3, -1, -1,  3,  1, -2, -1, -1, -1, -1, -1, -1, -1],\n",
        "       [1,  -1 ,-2 ,-2 ,-1 ,-1, -3, -3, -1, -1,  4,  3, -2,  0,  0, -1, -1, -1, -1, -1],\n",
        "       [0,   6, -4, -4, -3 ,-3, -3, -3, -2, -3,  0, -2, -3, -1, -2, -2, -2, -3, -2, -2],\n",
        "       [0,  -3 , 1,  4,  1 , 2,  0, -2, -3, -1, -2, -1, -1, -3, -2, -3, -2, -2, -4, -3],\n",
        "       [2,   0 ,-2, -2, -1, -2, -3, -3, -1, -1,  4,  1, -2,  0,  0, -1,  0, -1, -1,  0],\n",
        "       [-2, -1 ,-3 ,-4 ,-3, -3, -4, -4, -2, -4,  0, -1, -3,  3,  0, -1, -1, -2,  6,  1],\n",
        "       [0 ,  6, -4, -4, -3, -3, -3, -3, -2, -3,  0, -2, -3, -1, -2, -2, -2, -3, -2, -2],\n",
        "       [1 , -1 ,-2 ,-2, -1, -1, -3, -2, -1, -2,  1,  3, -2,  0,  4, -1,  0,  0, -1,  0],\n",
        "       [0,  -2,  1, -1,  2,  0, -2, -3, -3, -1,  2,  3, -1, -1, -1, -2, -1, -2, -2, -1],\n",
        "       [0,  -3,  3,  1,  4,  1, -1, -3, -3, -1, -2,  0, -1, -3, -2, -3, -3, -3, -3, -3],\n",
        "       [0 , -1 ,-2, -2, -1, -1, -3, -3, -1, -2,  2,  3, -2,  0,  0, -1,  3,  1, -1,  0],\n",
        "       [0,  -3,  3,  1,  4,  1, -1, -3, -3, -1, -2,  0, -1, -3, -2, -3, -3, -3, -3, -3],\n",
        "       [3,   0, -2, -2, -1, -1, -3, -3, -1, -1,  3,  1, -2,  0,  0, -1, -1, -1, -1, -1]]\n",
        "    M = np.array(M).transpose()\n",
        "    M = M.reshape(-1,21,1)\n",
        "    #M = pd.DataFrame(data=M,index=res)\n",
        "    return M\n",
        "\n",
        "def position_values_to_scores(data):\n",
        "    \"\"\"\n",
        "    :param data: The data must already be treated by the load_data and the load(X) procedures\n",
        "    the transformation is made only using the features\n",
        "    :return: data with each position value replaced by its corespondent column in the scoring matrix\n",
        "    \"\"\"\n",
        "    assert type(data) == np.ndarray\n",
        "    assert data.shape[1] == janela\n",
        "    zeros = np.zeros((21,1),dtype=np.int32).tolist()\n",
        "    M = buildScoringMatrix()\n",
        "    newData = []\n",
        "    for i,res in enumerate(data):\n",
        "        newData.append([])\n",
        "        for j,amin in enumerate(res):\n",
        "            if amin != 0:\n",
        "                newData[i].append(M[amin-1,:].tolist())\n",
        "            else:\n",
        "                newData[i].append(zeros)\n",
        "\n",
        "    return np.array(newData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwQeKNSlc_lc",
        "colab_type": "text"
      },
      "source": [
        "### Model's Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fwk-2qbdEXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2DModel(input_shape,n_classes):\n",
        "  model = Sequential()\n",
        "  reg = 0.01\n",
        "  model.add(Conv2D(32,(3),input_shape=input_shape,use_bias=True,\n",
        "                   kernel_regularizer=regularizers.l2(reg),activation='relu'))\n",
        "  model.add(Conv2D(64,(3),use_bias=True,\n",
        "                   kernel_regularizer=regularizers.l2(reg),activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64,activation='relu',use_bias=True\n",
        "                  ,name=\"first_fc_layer\",kernel_regularizer=regularizers.l2(reg)))\n",
        "  model.add(Dense(128,activation='tanh',use_bias=True\n",
        "                  ,name=\"second_fc_layer\",kernel_regularizer=regularizers.l2(reg)))\n",
        "  model.add(Dense(128,activation='tanh',use_bias=True\n",
        "                  ,name=\"third_fc_layer\",kernel_regularizer=regularizers.l2(reg)))\n",
        "  model.add(Dense(64,activation='relu',use_bias=True\n",
        "                  ,name=\"fourch_fc_layer\",kernel_regularizer=regularizers.l2(reg)))\n",
        "  model.add(Dense(n_classes,activation='softmax',use_bias=True\n",
        "                        ,kernel_regularizer=regularizers.l2(reg)))\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HlZTTsTftp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2DResnet(input_shape, n_classes):\n",
        "    reg = 0.01\n",
        "\n",
        "    # First Skip Layer 64\n",
        "    X_input = Input(input_shape)\n",
        "    X_skip = Conv2D(32, (3),use_bias=True,\n",
        "                    kernel_regularizer=regularizers.l2(reg), activation='relu')(X_input)\n",
        "    X = Conv2D(32, (3), use_bias=True,padding='same',\n",
        "               kernel_regularizer=regularizers.l2(reg),activation='relu')(X_skip)\n",
        "    X = Add()([X_skip, X])\n",
        "    X = BatchNormalization()(X)\n",
        "\n",
        "    # Third Skip Layer 512\n",
        "    X_skip = Conv2D(64, (3), use_bias=True,\n",
        "                    kernel_regularizer=regularizers.l2(reg), activation='relu')(X)\n",
        "    X = Conv2D(64, (3), padding='same',use_bias=True, \n",
        "               kernel_regularizer=regularizers.l2(reg),activation='relu')(X_skip)\n",
        "    X = Add()([X_skip, X])\n",
        "    X = BatchNormalization()(X)\n",
        "    X = MaxPooling2D(2)(X)\n",
        "\n",
        "    # Fully Connected part\n",
        "\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(64, activation='relu', name=\"first_fc_layer\", use_bias=True,\n",
        "              kernel_regularizer=regularizers.l2(reg))(X)\n",
        "    X = Dense(128, activation='relu', name=\"second_fc_layer\", use_bias=True,\n",
        "              kernel_regularizer=regularizers.l2(reg))(X)\n",
        "    X = Dense(64, activation='relu', name=\"third_fc_layer\", use_bias=True,\n",
        "              kernel_regularizer=regularizers.l2(reg))(X)\n",
        "    X = Dense(n_classes, activation='softmax', name=\"class\", use_bias=True\n",
        "              , kernel_regularizer=regularizers.l2(reg))(X)\n",
        "\n",
        "    model = Model(inputs=X_input, outputs=X, name=\"Conv1DResnet\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmLD9hkhdGDQ",
        "colab_type": "text"
      },
      "source": [
        "### Model's Training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGrutOryZhiQ",
        "colab_type": "code",
        "outputId": "28b7edcc-5a44-4939-ec1f-815894b6c9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = load_data()\n",
        "\n",
        "coil = data.loc[data['Class'] == 0]\n",
        "fita = data.loc[data['Class'] == 1]\n",
        "helice = data.loc[data['Class'] == 2]\n",
        "\n",
        "print(len(coil)/len(data))\n",
        "print(len(fita)/len(data))\n",
        "print(len(helice)/len(data))\n",
        "sns.countplot(x='Class', data=data, palette='RdBu')\n",
        "\n",
        "X = data.drop(['Class'], axis=1)\n",
        "y = data['Class']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "       Element0  Element1  Element2  ...  Element23  Element24  Class\n",
            "0             0         0         0  ...         20         11      0\n",
            "1             0         0         0  ...         11          5      0\n",
            "2             0         0         0  ...          5         19      1\n",
            "3             0         0         0  ...         19          1      1\n",
            "4             0         0         0  ...          1         13      1\n",
            "5             0         0         0  ...         13         12      1\n",
            "6             0         0         0  ...         12          2      1\n",
            "7             0         0         0  ...          2         12      1\n",
            "8             0         0         0  ...         12          4      1\n",
            "9             0         0         0  ...          4         12      1\n",
            "10            0         0        16  ...         12          8      1\n",
            "11            0        16        14  ...          8         18      1\n",
            "12           16        14         8  ...         18         11      1\n",
            "13           14         8        15  ...         11          6      1\n",
            "14            8        15         7  ...          6          8      1\n",
            "15           15         7        20  ...          8         12      0\n",
            "16            7        20         9  ...         12          6      0\n",
            "17           20         9        19  ...          6         14      0\n",
            "18            9        19         4  ...         14          5      0\n",
            "19           19         4        18  ...          5         13      0\n",
            "20            4        18         4  ...         13          6      0\n",
            "21           18         4        20  ...          6         13      1\n",
            "22            4        20        11  ...         13         17      1\n",
            "23           20        11         5  ...         17          8      1\n",
            "24           11         5        19  ...          8         15      1\n",
            "25            5        19         1  ...         15          1      1\n",
            "26           19         1        13  ...          1         12      1\n",
            "27            1        13        12  ...         12          1      0\n",
            "28           13        12         2  ...          1          6      0\n",
            "29           12         2        12  ...          6          3      1\n",
            "...         ...       ...       ...  ...        ...        ...    ...\n",
            "11943         9        18        17  ...          3         18      0\n",
            "11944        18        17        18  ...         18          5      0\n",
            "11945        17        18        13  ...          5          8      0\n",
            "11946        18        13        10  ...          8         12      0\n",
            "11947        13        10         5  ...         12          1      0\n",
            "11948        10         5         4  ...          1          6      0\n",
            "11949         5         4         6  ...          6          8      2\n",
            "11950         4         6        18  ...          8          9      2\n",
            "11951         6        18        14  ...          9          6      2\n",
            "11952        18        14         9  ...          6          4      2\n",
            "11953        14         9        17  ...          4          4      2\n",
            "11954         9        17        14  ...          4         20      2\n",
            "11955        17        14        17  ...         20          3      2\n",
            "11956        14        17         8  ...          3          1      2\n",
            "11957        17         8        15  ...          1          1      2\n",
            "11958         8        15        16  ...          1         19      2\n",
            "11959        15        16         1  ...         19         12      0\n",
            "11960        16         1        16  ...         12         16      0\n",
            "11961         1        16         3  ...         16          0      0\n",
            "11962        16         3         8  ...          0          0      0\n",
            "11963         3         8        15  ...          0          0      2\n",
            "11964         8        15         3  ...          0          0      2\n",
            "11965        15         3        18  ...          0          0      2\n",
            "11966         3        18         5  ...          0          0      2\n",
            "11967        18         5         8  ...          0          0      2\n",
            "11968         5         8        12  ...          0          0      2\n",
            "11969         8        12         1  ...          0          0      2\n",
            "11970        12         1         6  ...          0          0      2\n",
            "11971         1         6         8  ...          0          0      0\n",
            "11972         6         8         9  ...          0          0      0\n",
            "\n",
            "[11973 rows x 26 columns]\n",
            "0.4143489518082352\n",
            "0.2382861438236031\n",
            "0.3473649043681617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAENCAYAAADOhVhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_NcpxJcZhil",
        "colab_type": "code",
        "outputId": "102995dc-400a-48c0-b67a-328201b927d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X = np.asarray(X)\n",
        "\n",
        "X = position_values_to_scores(X)\n",
        "\n",
        "\n",
        "#standardizing data ====================================\n",
        "sample_height = X.shape[1]\n",
        "sample_width = X.shape[2]\n",
        "last_column = 1\n",
        "\n",
        "X  = X.reshape(-1,X.shape[1]*X.shape[2]*X.shape[3])\n",
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "X = scaler.transform(X)\n",
        "X = X.reshape(-1,sample_height,sample_width,last_column)\n",
        "#=======================================================\n",
        "\n",
        "\n",
        "X,y = sklearn.utils.shuffle([X,y])\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 3)\n",
        "y_test = keras.utils.to_categorical(y_test, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11973, 25, 21, 1)\n",
            "(11973,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IplKmU83xq2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model,hist,X_test,y_test,batch_size,epochs):\n",
        "    predictions = model.predict(X_test, batch_size=batch_size)\n",
        "    value = classification_report(y_test.argmax(axis=1),\n",
        "                                  predictions.argmax(axis=1))\n",
        "    print(value)\n",
        "\n",
        "    # plot the training loss and accuracy\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    # plt.xscale('log')\n",
        "    # plt.yscale('log')\n",
        "    plt.ylim((0, 1))\n",
        "    plt.plot(np.arange(0, epochs), hist.history[\"acc\"], label=\"train_acc\")\n",
        "    plt.plot(np.arange(0, epochs), hist.history[\"val_acc\"], label=\"val_acc\")\n",
        "    plt.title(\"Training and validation Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LDIkYPchZhjk",
        "colab_type": "code",
        "outputId": "d58e409e-3ffc-4c85-f5b0-6df229baeff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size=512\n",
        "input_shape = X.shape[1:]\n",
        "print(\"Data shape\",input_shape)\n",
        "#model = conv2DModel(input_shape,3)\n",
        "model = conv2DResnet(input_shape,3)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=.01,momentum=.5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
        "\n",
        "evaluate_model(model, hist, X_test, y_test, batch_size, epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape (25, 21, 1)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 25, 21, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 23, 19, 32)   320         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 23, 19, 32)   9248        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 23, 19, 32)   0           conv2d_65[0][0]                  \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 23, 19, 32)   128         add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 21, 17, 64)   18496       batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 21, 17, 64)   36928       conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 21, 17, 64)   0           conv2d_67[0][0]                  \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 21, 17, 64)   256         add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 10, 8, 64)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 5120)         0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "first_fc_layer (Dense)          (None, 64)           327744      flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "second_fc_layer (Dense)         (None, 128)          8320        first_fc_layer[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "third_fc_layer (Dense)          (None, 64)           8256        second_fc_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "class (Dense)                   (None, 3)            195         third_fc_layer[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 409,891\n",
            "Trainable params: 409,699\n",
            "Non-trainable params: 192\n",
            "__________________________________________________________________________________________________\n",
            "Train on 9578 samples, validate on 2395 samples\n",
            "Epoch 1/20\n",
            "9578/9578 [==============================] - 4s 446us/step - loss: 5.5019 - acc: 0.3958 - val_loss: 5.4334 - val_acc: 0.4301\n",
            "Epoch 2/20\n",
            "9578/9578 [==============================] - 1s 98us/step - loss: 5.3751 - acc: 0.4667 - val_loss: 5.3452 - val_acc: 0.4593\n",
            "Epoch 3/20\n",
            "9578/9578 [==============================] - 1s 97us/step - loss: 5.2742 - acc: 0.5038 - val_loss: 5.2657 - val_acc: 0.4777\n",
            "Epoch 4/20\n",
            "9578/9578 [==============================] - 1s 97us/step - loss: 5.1771 - acc: 0.5323 - val_loss: 5.1876 - val_acc: 0.4877\n",
            "Epoch 5/20\n",
            "9578/9578 [==============================] - 1s 97us/step - loss: 5.0830 - acc: 0.5635 - val_loss: 5.1184 - val_acc: 0.4939\n",
            "Epoch 6/20\n",
            "9578/9578 [==============================] - 1s 97us/step - loss: 4.9954 - acc: 0.5772 - val_loss: 5.0435 - val_acc: 0.5048\n",
            "Epoch 7/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.9044 - acc: 0.5998 - val_loss: 4.9741 - val_acc: 0.5165\n",
            "Epoch 8/20\n",
            "9578/9578 [==============================] - 1s 98us/step - loss: 4.8235 - acc: 0.6157 - val_loss: 4.9139 - val_acc: 0.5203\n",
            "Epoch 9/20\n",
            "9578/9578 [==============================] - 1s 98us/step - loss: 4.7326 - acc: 0.6426 - val_loss: 4.8711 - val_acc: 0.5081\n",
            "Epoch 10/20\n",
            "9578/9578 [==============================] - 1s 98us/step - loss: 4.6534 - acc: 0.6554 - val_loss: 4.7806 - val_acc: 0.5357\n",
            "Epoch 11/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.5831 - acc: 0.6658 - val_loss: 4.7191 - val_acc: 0.5353\n",
            "Epoch 12/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.4968 - acc: 0.6853 - val_loss: 4.6645 - val_acc: 0.5432\n",
            "Epoch 13/20\n",
            "9578/9578 [==============================] - 1s 98us/step - loss: 4.4351 - acc: 0.6861 - val_loss: 4.6095 - val_acc: 0.5478\n",
            "Epoch 14/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.3567 - acc: 0.6998 - val_loss: 4.5318 - val_acc: 0.5649\n",
            "Epoch 15/20\n",
            "9578/9578 [==============================] - 1s 98us/step - loss: 4.3237 - acc: 0.6857 - val_loss: 4.5150 - val_acc: 0.5399\n",
            "Epoch 16/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.2640 - acc: 0.7035 - val_loss: 4.4396 - val_acc: 0.5612\n",
            "Epoch 17/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.1456 - acc: 0.7368 - val_loss: 4.4337 - val_acc: 0.5303\n",
            "Epoch 18/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.1341 - acc: 0.7117 - val_loss: 4.3185 - val_acc: 0.5775\n",
            "Epoch 19/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 4.0499 - acc: 0.7324 - val_loss: 4.2798 - val_acc: 0.5749\n",
            "Epoch 20/20\n",
            "9578/9578 [==============================] - 1s 99us/step - loss: 3.9571 - acc: 0.7576 - val_loss: 4.3198 - val_acc: 0.5336\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.41      0.51       995\n",
            "           1       0.62      0.27      0.38       597\n",
            "           2       0.47      0.88      0.61       803\n",
            "\n",
            "    accuracy                           0.53      2395\n",
            "   macro avg       0.58      0.52      0.50      2395\n",
            "weighted avg       0.59      0.53      0.51      2395\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIS9Q/ITy5PUkKYKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG4kJ4T11Cpz",
        "colab_type": "code",
        "outputId": "4ce14d90-fe2b-4017-ae16-b8d93ecae224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "p = [ np.argmax(p)  for p in predictions]\n",
        "df = pd.DataFrame(p,index=['class'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 1691\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (2395, 1), indices imply (1, 1)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-565738cc9d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                     mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 451\u001b[0;31m                                        copy=copy)\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 1691\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (2395, 1), indices imply (1, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24QtamTpZhj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as k\n",
        "k.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42jqxQK7ZhkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X = data.drop(['Class'], axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(confusion_matrix(y_test, clf.predict(X_test)))\n",
        "print(classification_report(y_test, clf.predict(X_test)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}